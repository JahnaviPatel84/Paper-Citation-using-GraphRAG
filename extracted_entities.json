{
    "nodes": [
        {
            "id": "1|38|24|15",
            "label": "Recurrent Language Models",
            "type": "Concept",
            "summary": "Typically factor computation along the symbol positions of the input and output sequences."
        },
        {
            "id": "2|38|24|15",
            "label": "Encoder-Decoder Architectures",
            "type": "Concept",
            "summary": "Typically factor computation along the symbol positions of the input and output sequences."
        },
        {
            "id": "3|21|32",
            "label": "Factorization Tricks",
            "type": "Method",
            "summary": "Achieve significant improvements in computational efficiency through factorization."
        },
        {
            "id": "4|21|32",
            "label": "Conditional Computation",
            "type": "Method",
            "summary": "Achieve significant improvements in computational efficiency and model performance."
        },
        {
            "id": "5|2|19",
            "label": "Attention Mechanisms",
            "type": "Concept",
            "summary": "Allow modeling of dependencies without regard to their distance in the input or output sequences."
        },
        {
            "id": "6|27|2|19",
            "label": "Sequence Modeling",
            "type": "Concept",
            "summary": "Allow modeling of dependencies without regard to their distance in the input or output sequences."
        },
        {
            "id": "7|16|18|9",
            "label": "Extended Neural GPU",
            "type": "Concept",
            "summary": "A model architecture that reduces sequential computation."
        },
        {
            "id": "8|16|18|9",
            "label": "ByteNet",
            "type": "Concept",
            "summary": "A model architecture that reduces sequential computation."
        },
        {
            "id": "9|16|18|9",
            "label": "ConvS2S",
            "type": "Concept",
            "summary": "A model architecture that reduces sequential computation."
        },
        {
            "id": "10|4|27|28|22",
            "label": "Self-Attention Mechanism",
            "type": "Method",
            "summary": "Relate different positions of a single sequence in order to compute a representation of the sequence."
        },
        {
            "id": "11|34|10",
            "label": "End-to-End Memory Networks",
            "type": "Concept",
            "summary": "Based on a recurrent attention mechanism instead of sequence-aligned recurrence."
        },
        {
            "id": "12|17|18|9",
            "label": "Transformer",
            "type": "Concept",
            "summary": "A model architecture that eschews recurrence and relies entirely on an attention mechanism."
        }
    ],
    "edges": [
        {
            "source": "1|38|24|15",
            "target": "2|38|24|15",
            "label": "Comprises"
        },
        {
            "source": "2|38|24|15",
            "target": "3|21|32",
            "label": "Achieves"
        },
        {
            "source": "2|38|24|15",
            "target": "4|21|32",
            "label": "Employ"
        },
        {
            "source": "2|38|24|15",
            "target": "5|2|19",
            "label": "Uses"
        },
        {
            "source": "2|38|24|15",
            "target": "6|27|2|19",
            "label": "Improves"
        },
        {
            "source": "7|16|18|9",
            "target": "8|16|18|9",
            "label": "Extends"
        },
        {
            "source": "8|16|18|9",
            "target": "9|16|18|9",
            "label": "Inspires"
        },
        {
            "source": "9|16|18|9",
            "target": "12|17|18|9",
            "label": "Motivates"
        },
        {
            "source": "10|4|27|28|22",
            "target": "5|2|19",
            "label": "Relies on"
        },
        {
            "source": "11|34|10",
            "target": "10|4|27|28|22",
            "label": "employs"
        },
        {
            "source": "12|17|18|9",
            "target": "10|4|27|28|22",
            "label": "Employs"
        }
    ]
}